{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "19d1ddb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831cca90",
   "metadata": {},
   "source": [
    "# Code to combine DAMASMCPC price data from 2022 to 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "955fa627",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_hour_ending(row):\n",
    "    if row[\"Hour Ending\"] == \"24:00\":\n",
    "        return row[\"Delivery Date\"] + pd.Timedelta(days=1)\n",
    "    else:\n",
    "        time = pd.to_datetime(row[\"Hour Ending\"], format=\"%H:%M\").time()\n",
    "        return pd.Timestamp.combine(row[\"Delivery Date\"], time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8b32626b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_single_file(filepath):\n",
    "    df = pd.read_csv(filepath)\n",
    "    df.columns = df.columns.str.strip()\n",
    "    df[\"Delivery Date\"] = pd.to_datetime(df[\"Delivery Date\"], format=\"%m/%d/%Y\")\n",
    "    df[\"datetime_col\"] = df.apply(fix_hour_ending, axis=1)\n",
    "    df.drop(columns=[\"Delivery Date\", \"Hour Ending\", \"Repeated Hour Flag\"], inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "93ec44e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved cleaned and combined dataset to: ./data/prices/DAMASMCPC_2022_to_2025.csv\n"
     ]
    }
   ],
   "source": [
    "years = [2022, 2023, 2024, 2025]\n",
    "base_path = \"./data/prices/raw/\"\n",
    "files = [os.path.join(base_path, f\"DAMASMCPC_{year}.csv\") for year in years]\n",
    "\n",
    "all_dfs = [process_single_file(file) for file in files]\n",
    "combined_df = pd.concat(all_dfs, ignore_index=True)\n",
    "combined_df = combined_df.sort_values(\"datetime_col\").reset_index(drop=True)\n",
    "\n",
    "# Reorder columns\n",
    "reordered_cols = ['datetime_col'] + [col for col in combined_df.columns if col != 'datetime_col']\n",
    "combined_df = combined_df[reordered_cols]\n",
    "\n",
    "# Save to new file\n",
    "output_path = \"./data/prices/DAMASMCPC_2022_to_2025.csv\"\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "combined_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"âœ… Saved cleaned and combined dataset to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c89d5f",
   "metadata": {},
   "source": [
    "# Code to combine DAMLZHBSPP price data from 2022 to 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91afa293",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_hour_ending(row):\n",
    "    if row[\"Hour Ending\"] == \"24:00\":\n",
    "        return pd.to_datetime(row[\"Delivery Date\"], format=\"%m/%d/%Y\") + pd.Timedelta(days=1)\n",
    "    else:\n",
    "        time = pd.to_datetime(row[\"Hour Ending\"], format=\"%H:%M\").time()\n",
    "        date = pd.to_datetime(row[\"Delivery Date\"], format=\"%m/%d/%Y\")\n",
    "        return pd.Timestamp.combine(date, time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "993a4a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_single_excel(xlsx_path: str) -> pd.DataFrame:\n",
    "    # Load Excel file\n",
    "    df = pd.read_excel(xlsx_path)\n",
    "    df.columns = df.columns.str.strip()\n",
    "\n",
    "    # Create datetime column\n",
    "    df[\"datetime_col\"] = df.apply(fix_hour_ending, axis=1)\n",
    "\n",
    "    # Pivot SPPs into columns\n",
    "    pivot_df = df.pivot_table(\n",
    "        index=\"datetime_col\",\n",
    "        columns=\"Settlement Point\",\n",
    "        values=\"Settlement Point Price\"\n",
    "    ).reset_index()\n",
    "\n",
    "    return pivot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4ea441c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ Processing: ./data/prices/raw/DAMLZHBSPP_2022.xlsx\n",
      "ðŸ“‚ Processing: ./data/prices/raw/DAMLZHBSPP_2023.xlsx\n",
      "ðŸ“‚ Processing: ./data/prices/raw/DAMLZHBSPP_2024.xlsx\n",
      "ðŸ“‚ Processing: ./data/prices/raw/DAMLZHBSPP_2025.xlsx\n",
      "\n",
      "âœ… Saved combined file to: data/prices/DAMLZHBSPP_2022_to_2025.csv\n"
     ]
    }
   ],
   "source": [
    "years = [2022, 2023, 2024, 2025]\n",
    "input_dir = \"./data/prices/raw/\"\n",
    "output_path = \"data/prices/DAMLZHBSPP_2022_to_2025.csv\"\n",
    "\n",
    "all_dfs = []\n",
    "for year in years:\n",
    "    file_path = os.path.join(input_dir, f\"DAMLZHBSPP_{year}.xlsx\")\n",
    "    print(f\"ðŸ“‚ Processing: {file_path}\")\n",
    "    yearly_df = process_single_excel(file_path)\n",
    "    all_dfs.append(yearly_df)\n",
    "\n",
    "# concatenate and sort chronologically\n",
    "combined_df = pd.concat(all_dfs, ignore_index=True)\n",
    "combined_df = combined_df.sort_values(\"datetime_col\").reset_index(drop=True)\n",
    "\n",
    "# save to CSV\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "combined_df.to_csv(output_path, index=False)\n",
    "print(f\"\\nâœ… Saved combined file to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c659e401",
   "metadata": {},
   "source": [
    "# Code to combine RTMLZHBSPP price data from 2022 to 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f89dd748",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_15min_excel_file(xlsx_path: str) -> pd.DataFrame:\n",
    "    df = pd.read_excel(xlsx_path)\n",
    "    df.columns = df.columns.str.strip()\n",
    "    df[\"Delivery Date\"] = pd.to_datetime(df[\"Delivery Date\"], format=\"%m/%d/%Y\")\n",
    "\n",
    "    # Map Delivery Interval to minutes\n",
    "    interval_to_minute = {1: 0, 2: 15, 3: 30, 4: 45}\n",
    "    df[\"minute\"] = df[\"Delivery Interval\"].map(interval_to_minute)\n",
    "\n",
    "    # Compute datetime_col from Delivery Date, Hour, and Interval\n",
    "    df[\"datetime_col\"] = df.apply(\n",
    "        lambda row: row[\"Delivery Date\"] + pd.Timedelta(hours=row[\"Delivery Hour\"] - 1, minutes=row[\"minute\"]),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Pivot: Each Settlement Point Name becomes its own column\n",
    "    pivot_df = df.pivot_table(\n",
    "        index=\"datetime_col\",\n",
    "        columns=\"Settlement Point Name\",\n",
    "        values=\"Settlement Point Price\"\n",
    "    ).reset_index()\n",
    "\n",
    "    return pivot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29ecaa0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ Processing: ./data/prices/raw/RTMLZHBSPP_2022.xlsx\n",
      "ðŸ“‚ Processing: ./data/prices/raw/RTMLZHBSPP_2023.xlsx\n",
      "ðŸ“‚ Processing: ./data/prices/raw/RTMLZHBSPP_2024.xlsx\n",
      "ðŸ“‚ Processing: ./data/prices/raw/RTMLZHBSPP_2025.xlsx\n",
      "\n",
      "âœ… Saved combined 15-min interval file to: ./data/prices/RTMLZHBSPP_2022_to_2025.csv\n"
     ]
    }
   ],
   "source": [
    "years = [2022, 2023, 2024, 2025]\n",
    "input_dir = \"./data/prices/raw/\"\n",
    "output_path = \"./data/prices/RTMLZHBSPP_2022_to_2025.csv\"\n",
    "\n",
    "all_dfs = []\n",
    "for year in years:\n",
    "    file_path = os.path.join(input_dir, f\"RTMLZHBSPP_{year}.xlsx\")\n",
    "    print(f\"ðŸ“‚ Processing: {file_path}\")\n",
    "    yearly_df = process_15min_excel_file(file_path)\n",
    "    all_dfs.append(yearly_df)\n",
    "\n",
    "# Combine and sort chronologically\n",
    "combined_df = pd.concat(all_dfs, ignore_index=True)\n",
    "combined_df = combined_df.sort_values(\"datetime_col\").reset_index(drop=True)\n",
    "\n",
    "# Save to CSV\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "combined_df.to_csv(output_path, index=False)\n",
    "print(f\"\\nâœ… Saved combined 15-min interval file to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949df3fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "te_forecasting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
