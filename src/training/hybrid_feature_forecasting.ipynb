{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e8b9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install packages\n",
    "\n",
    "!pip install gridstatus statsmodels pandas matplotlib\n",
    "!pip install -q gdown\n",
    "!pip install --upgrade --quiet \\\n",
    "    numpy==1.26.4 \\\n",
    "    pandas==2.2.2 \\\n",
    "    scikit-learn==1.3.2 \\\n",
    "    xgboost==2.0.3 \\\n",
    "    lightgbm==4.1.0 \\\n",
    "    catboost==1.2.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85062cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements\n",
    "from datetime import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gridstatus import Ercot\n",
    "import xgboost as xgb\n",
    "\n",
    "ercot = Ercot()\n",
    "\n",
    "from pathlib import Path\n",
    "base_path = Path.home() / \"Documents\" / \"totalenergies_price_forecasting\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ef7e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feat(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    X = df.loc[:, df.columns != 'Price ($/MWh)'] \n",
    "    y = df['Price ($/MWh)']\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57bc39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_forecast(feature, X, y, fh, ml): \n",
    "  print(f\"Training univariate forecaster for feature: {feature}\")\n",
    "   \n",
    "  # create lagged versions of the feature\n",
    "  for lag in range(1, ml + 1):\n",
    "    X[f\"{feature}_lag{lag}\"] = X[feature].shift(lag)\n",
    "     \n",
    "  feature_lagged = X[[f\"{feature}_lag{lag}\" for lag in range(1, ml + 1)]].dropna()  # drop NaNs\n",
    "  y_target = X[feature].shift(-fh).dropna()\n",
    "     \n",
    "  # align X and y (must use common indices)\n",
    "  common_idx = feature_lagged.index.intersection(y_target.index)\n",
    "  X_feat = feature_lagged.loc[common_idx]\n",
    "  y_feat = y_target.loc[common_idx]\n",
    "\n",
    "  train_size = int(0.8 * len(X_feat))\n",
    "  X_feat_train, X_feat_test = X_feat.iloc[:train_size], X_feat.iloc[train_size:]\n",
    "  y_feat_train, y_feat_test = y_feat.iloc[:train_size], y_feat.iloc[train_size:]\n",
    "\n",
    "  model = xgb.XGBRegressor(objective=\"reg:squarederror\", n_estimators=50) \n",
    "  model.fit(X_feat_train, y_feat_train)  # train model\n",
    "\n",
    "  # predict future forecast_horizon steps using most recent lag features\n",
    "  last_known = X[[f\"{feature}_lag{lag}\" for lag in range(1, ml + 1)]].iloc[-fh:]\n",
    "\n",
    "  feature_preds = model.predict(last_known)  # make prediction\n",
    "  return feature_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81685996",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_shift(X, y, fh, discard):\n",
    "    y_shifted = y.shift(-fh)\n",
    "    # drop rows with NaNs caused by shift (they occur at the end)\n",
    "    valid_idx = y_shifted.dropna().index\n",
    "\n",
    "    # align X and y so that input X[t] corresponds to output y[t+horizon]\n",
    "    X_supervised = X.loc[valid_idx]\n",
    "    for col in discard:\n",
    "        X_supervised = X_supervised.drop(col, axis=1)\n",
    "    y_supervised = y_shifted.loc[valid_idx]\n",
    "\n",
    "    # Print the shapes to confirm\n",
    "    print(f\"Shape of X_supervised: {X_supervised.shape}\")\n",
    "    print(f\"Shape of y_supervised: {y_supervised.shape}\")\n",
    "\n",
    "    # Optional: Reset index if you want a clean DataFrame\n",
    "    X_supervised = X_supervised.reset_index(drop=True)\n",
    "    y_supervised = y_supervised.reset_index(drop=True)\n",
    "\n",
    "    return X_supervised, y_supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb95d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_feature_forecast(file_path, dynamic_features, forecast_horizon, max_lag):\n",
    "    X, y = get_feat(file_path)\n",
    "    predicted_features = pd.DataFrame() \n",
    "\n",
    "    for feat in dynamic_features:\n",
    "        feature_preds = feat_forecast(feat, X, y, forecast_horizon, max_lag)\n",
    "        predicted_features[feat] = feature_preds\n",
    "    \n",
    "    X_supervised, y_supervised = time_shift(X, y, forecast_horizon, dynamic_features)\n",
    "    \n",
    "    assert predicted_features.shape[0] == X_supervised.shape[0]\n",
    "\n",
    "    # Add suffix to predicted features to indicate they are forecasts\n",
    "    predicted_features = predicted_features.add_suffix('_forecast')\n",
    "\n",
    "    # Concatenate original X_supervised with forecasted weather features\n",
    "    X_combined = pd.concat([X_supervised, predicted_features], axis=1)\n",
    "\n",
    "    return X_combined, y_supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a460239",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_horizon = 48\n",
    "max_lag = 24\n",
    "\n",
    "file_path = base_path / \"data\" / \"processed\" / \"\"\n",
    "dynamic_features = []"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
